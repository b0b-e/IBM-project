{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "LRAtR8iUyA2E",
      "metadata": {
        "id": "LRAtR8iUyA2E"
      },
      "source": [
        "# Emotion Analysis Model Training\n",
        "This notebook trains TF‑IDF + Logistic Regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9MY-_a8VyA2F",
      "metadata": {
        "id": "9MY-_a8VyA2F"
      },
      "outputs": [],
      "source": [
        "import os, re, joblib\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "mSeuSCK4yA2G",
      "metadata": {
        "id": "mSeuSCK4yA2G"
      },
      "outputs": [],
      "source": [
        "PROJECT_ROOT = Path().resolve()\n",
        "DATA_DIR = PROJECT_ROOT / 'Dataset'\n",
        "MODEL_DIR = PROJECT_ROOT / 'Model'\n",
        "MODEL_DIR.mkdir(exist_ok=True)\n",
        "MAX_FEAT = 12000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "z199NrjzyA2G",
      "metadata": {
        "id": "z199NrjzyA2G"
      },
      "outputs": [],
      "source": [
        "def clean_text(s):\n",
        "    if not isinstance(s, str): return ''\n",
        "    s = re.sub(r'http\\S+', '', s)\n",
        "    s = re.sub(r\"’\", \"'\", s)\n",
        "    s = re.sub(r\"[^A-Za-z0-9\\s'\\-]\", ' ', s)\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "    return s.lower()\n",
        "\n",
        "def expand_contractions(text):\n",
        "    contractions = {\"can't\":\"can not\",\"won't\":\"will not\",\"n't\":\" not\",\n",
        "                    \"i'm\":\"i am\",\"it's\":\"it is\",\"that's\":\"that is\",\n",
        "                    \"i've\":\"i have\",\"i'd\":\"i would\",\"you're\":\"you are\"}\n",
        "    for k,v in contractions.items():\n",
        "        text = re.sub(r'\\b'+re.escape(k)+r'\\b', v, text)\n",
        "    return text\n",
        "\n",
        "def handle_negations(text):\n",
        "    text = expand_contractions(text)\n",
        "    words = text.split()\n",
        "    out, neg = [], False\n",
        "    neg_tokens = {'not','no','never','cannot','cant',\"won't\"}\n",
        "    for w in words:\n",
        "        lw = w.lower()\n",
        "        if neg:\n",
        "            out.append('not_'+lw); neg=False; continue\n",
        "        if lw in neg_tokens or lw.endswith(\"n't\"):\n",
        "            neg=True; continue\n",
        "        out.append(lw)\n",
        "    return ' '.join(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "xGn50E6vyA2G",
      "metadata": {
        "id": "xGn50E6vyA2G"
      },
      "outputs": [],
      "source": [
        "train=pd.read_csv(DATA_DIR/'train.txt',sep=';',names=['text','emotion'])\n",
        "test=pd.read_csv(DATA_DIR/'test.txt',sep=';',names=['text','emotion'])\n",
        "val=pd.read_csv(DATA_DIR/'val.txt',sep=';',names=['text','emotion'])\n",
        "df=pd.concat([train,test,val]).reset_index(drop=True)\n",
        "df['text']=df['text'].astype(str).apply(clean_text).apply(handle_negations)\n",
        "le=LabelEncoder(); df['label']=le.fit_transform(df['emotion'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9J_ox7MIyA2G",
      "metadata": {
        "id": "9J_ox7MIyA2G"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(df['text'],df['label'],test_size=0.2,random_state=42,stratify=df['label'])\n",
        "vectorizer=TfidfVectorizer(max_features=MAX_FEAT,ngram_range=(1,2),sublinear_tf=True)\n",
        "X_tr=vectorizer.fit_transform(X_train)\n",
        "X_te=vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "pgHhjjMLyA2G",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgHhjjMLyA2G",
        "outputId": "1c2ed1fc-6eb4-4852-edd1-3c37a9f9273f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8585933630510153\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.82      0.87      0.84       545\n",
            "        fear       0.86      0.79      0.83       482\n",
            "         joy       0.90      0.87      0.88      1359\n",
            "        love       0.71      0.86      0.78       335\n",
            "     sadness       0.94      0.86      0.90      1166\n",
            "    surprise       0.61      0.91      0.73       151\n",
            "\n",
            "    accuracy                           0.86      4038\n",
            "   macro avg       0.81      0.86      0.83      4038\n",
            "weighted avg       0.87      0.86      0.86      4038\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model=LogisticRegression(max_iter=2000,class_weight='balanced',solver='saga')\n",
        "model.fit(X_tr,y_train)\n",
        "pred=model.predict(X_te)\n",
        "print('Accuracy:',accuracy_score(y_test,pred))\n",
        "print(classification_report(y_test,pred,target_names=le.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "jdbeesh6yA2G",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdbeesh6yA2G",
        "outputId": "394e77aa-f205-45a9-c2e0-393f3611737e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/Model/label_encoder.pkl']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(model, MODEL_DIR/'emotion_model.pkl')\n",
        "joblib.dump(vectorizer, MODEL_DIR/'tfidf_vectorizer.pkl')\n",
        "joblib.dump(le, MODEL_DIR/'label_encoder.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "pNmcehoDzdd_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNmcehoDzdd_",
        "outputId": "82d31b1b-b701-44ad-ece4-63f37ede7f7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEMO PREDICTIONS\n",
            "\n",
            "Text: I am extremely happy today!\n",
            "Predicted Emotion: joy (62.71% confidence)\n",
            "------------------------------------------------------------\n",
            "Text: This is not good at all.\n",
            "Predicted Emotion: surprise (52.91% confidence)\n",
            "------------------------------------------------------------\n",
            "Text: I’m furious right now.\n",
            "Predicted Emotion: anger (70.22% confidence)\n",
            "------------------------------------------------------------\n",
            "Text: Everything feels hopeless.\n",
            "Predicted Emotion: sadness (67.61% confidence)\n",
            "------------------------------------------------------------\n",
            "Text: I love spending time with you.\n",
            "Predicted Emotion: love (35.86% confidence)\n",
            "------------------------------------------------------------\n",
            "Text: I am terrified for tomorrow.\n",
            "Predicted Emotion: fear (78.43% confidence)\n",
            "------------------------------------------------------------\n",
            "Text: That's insane, how can that happen?\n",
            "Predicted Emotion: surprise (84.86% confidence)\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# --- Demo Predictions ---\n",
        "demo_sentences = [\n",
        "    \"I am extremely happy today!\",\n",
        "    \"This is not good at all.\",\n",
        "    \"I’m furious right now.\",\n",
        "    \"Everything feels hopeless.\",\n",
        "    \"I love spending time with you.\",\n",
        "    \"I am terrified for tomorrow.\",\n",
        "    \"That's insane, how can that happen?\"\n",
        "]\n",
        "\n",
        "# Clean + negation transform\n",
        "processed_demo = [handle_negations(clean_text(s)) for s in demo_sentences]\n",
        "\n",
        "# Vectorize and predict\n",
        "vec_demo = vectorizer.transform(processed_demo)\n",
        "pred_indices = model.predict(vec_demo)\n",
        "probabilities = model.predict_proba(vec_demo)\n",
        "\n",
        "# Display Predictions\n",
        "print(\"DEMO PREDICTIONS\\n\")\n",
        "for sentence, idx, prob_row in zip(demo_sentences, pred_indices, probabilities):\n",
        "    label = le.inverse_transform([idx])[0]\n",
        "    confidence = round(max(prob_row) * 100, 2)\n",
        "    print(f\"Text: {sentence}\")\n",
        "    print(f\"Predicted Emotion: {label} ({confidence}% confidence)\")\n",
        "    print(\"-\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
